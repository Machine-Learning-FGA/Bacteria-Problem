{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação da avaliação de modelos de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%autosave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comprimentocorpo' 'larguracorpo' 'comprimentoflagelo' 'larguraflagelo'\n",
      " 'Tipo' 'volumecorpo' 'volumeflagelo']\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset_bacteria.csv')\n",
    "dataset['volumecorpo'] = np.array(dataset['comprimentocorpo']) * np.pi*(np.array(dataset['larguracorpo'])/2)**2\n",
    "dataset['volumeflagelo'] = np.array(dataset['comprimentoflagelo']) * np.pi*(np.array(dataset['larguraflagelo'])/2)**2\n",
    "print(dataset.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando conjunto de teste e conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib # biblioteca para salvar os modelos\n",
    "\n",
    "Y = dataset.iloc[:, 4].values # Coluna Tipo\n",
    "X = dataset.iloc[:, [2, 3]].values # Features Selecionadas\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Modelo de classificação KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knnBacteria.sav']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "knn_classifier = neighbors.KNeighborsClassifier(5, 'uniform')\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Saving model to file\n",
    "joblib.dump(knn_classifier, 'knnBacteria.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Modelo de Classificação SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svmBacteria.sav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = SVC(kernel = 'rbf', gamma = 0.1)\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Saving model to file\n",
    "joblib.dump(svm_classifier, 'svmBacteria.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando modelos para avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  1 12]]\n",
      "\n",
      " [[13  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Importando modelo KNN\n",
    "knn_model = joblib.load('knnBacteria.sav')\n",
    "knn_y_pred = knn_model.predict(x_test)\n",
    "\n",
    "knn_confusion_matrix = confusion_matrix(y_test, knn_y_pred)\n",
    "print(knn_confusion_matrix)\n",
    "\n",
    "# Importando modelo SVM\n",
    "svm_model = joblib.load('svmBacteria.sav')\n",
    "svm_y_pred = svm_model.predict(x_test)\n",
    "\n",
    "svm_confusion_matrix = confusion_matrix(y_test, svm_y_pred)\n",
    "print('\\n', svm_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pelo método de _micro-averaging_ e _macro-averaging_ [1]\n",
    "\n",
    "Baseando-se pela matrix de confusão, pode-se calcular a precisão micro e precisão macro com a seguinte estratégia:\n",
    "\n",
    "Tomando a matriz de confusão como a abaixo:\n",
    "![img](https://qph.ec.quoracdn.net/main-qimg-e73665ad4501b9da6d5611e7b6d8e7a2 \"Matriz de Confusão\")\n",
    "\n",
    "Podemos calcular a precisão do modelo com a seguinte fórmula:\n",
    "$$ PRE = \\frac{TP} {(TP + FP)} $$\n",
    "\n",
    "E então generalizar a matriz de confusão de classificação binária para uma classificação multi-classe. Onde o calculo da _micro-average_ calcula a performance e precisão e a _macro-average_ calcula a média das performances de cada classe individualmente.\n",
    "\n",
    "Para a _micro-averaging_ utilizamos a fórmula:\n",
    "$$ PRE_{micro} = \\frac{TP_1 + ... + TP_n} {TP_1 + ... + TP_n + FP_1 + ... + FP_n} $$\n",
    "\n",
    "E para a _macro-averaging_ utilizamos a seguinte fórmula:\n",
    "$$ PRE_{macro} = \\frac{PRE_1 + ... + PRE_n} {n} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[1] Quora answer, Sebastian Raschka: [What are some good error metrics for multi-class classification when you have many objects to classify?](https://www.quora.com/What-are-some-good-error-metrics-for-multi-class-classification-when-you-have-many-objects-to-classify)   \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular o valor da precisão micro e macro\n",
    "def evaluation_micro_macro (confusion_matrix):\n",
    "    TP_all = 0\n",
    "    FP_all = 0\n",
    "    pre_all = 0\n",
    "    n_classes = confusion_matrix.shape[0]\n",
    "    for i in range(n_classes):\n",
    "        TP_all += confusion_matrix[i][i]\n",
    "        next_row = (i + 1) % n_classes\n",
    "        FP_all += confusion_matrix[i][next_row]\n",
    "        last_row = (i + 2) % n_classes\n",
    "        FP_all += confusion_matrix[i][last_row]\n",
    "        pre_all += confusion_matrix[i][i] / (confusion_matrix[i][i] + confusion_matrix[i][next_row] + knn_confusion_matrix[i][last_row])\n",
    "\n",
    "    pre_micro = TP_all / (TP_all + FP_all)\n",
    "    pre_macro = pre_all / len(classes)\n",
    "    \n",
    "    return (pre_micro, pre_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo de classificação SVM\n"
     ]
    }
   ],
   "source": [
    "# Avaliando o modelo KNN pela estratégia de micro e macro averaging\n",
    "mi_knn, ma_knn = evaluation_micro_macro(knn_confusion_matrix)\n",
    "\n",
    "# Avaliando o modelo SVM pela estratégia de micro e macro averaging\n",
    "mi_svm, ma_svm = evaluation_micro_macro(svm_confusion_matrix)\n",
    "\n",
    "# Utilizando o macro-averaging podemos escolher o melhor método\n",
    "# Já que o macro-averaging nos da um peso igual da classificação de cada classe\n",
    "print ('Melhor modelo de classificação', 'KNN' if ma_knn > ma_svm else 'SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pelo método de cálculo embaixo da curva ROC (_Receiving Operating Characteristic_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC** significa, em tradução livre, Características operacionais do receptor, e sua curva nada mais é que a demonstração gráfica que ilustra a habilidade do diagnóstico de um sistema de classificador binário, dessa forma pode-se inspecionar a performance do classificador.\n",
    "\n",
    "Esse método compara a taxa em que o classificador está fazendo predições corretas (Positivos verdadeiros) e a taxa em que o classificador está dando alarmes falsos (Falsos positivos). Para achar a taxa de positivos verdadeiros e falsos positivos, utilizamos a seguinte fórmula:\n",
    "\n",
    "$$ TPR = \\frac {TruePositives} {(TruePositives + FalseNegatives)} $$\n",
    "\n",
    "$$ FPR = \\frac {FalsePositives} {(FalsePositives + TrueNegatives)} $$\n",
    "\n",
    "Onde $TPR$ é a nossa taxa de positivos verdadeiros e $FPR$ a de falsos positivos. Com isso podemos medir corretamente o _trade off_ da taxa em que o classificador consegue predizer corretamente algo com a taxa em que ele erra em sua predição.\n",
    "\n",
    "Para entender a curva ROC temos primeiro que definir o que é um bom resultado para um classificador. Um classificador que faz predições ao acaso (aleátoriamente), consegue estar correto apenas 50% do tempo (lembrando que estamos falando de classificadores binários), dessa forma o gráfico de predição desse classificador seria uma reta diagonal. \n",
    "![classificador random](http://blog.yhat.com/static/img/roc-guessing.png 'classificador aleatório')\n",
    "\n",
    "Então podemos dizer que qualquer outra curva que esteja acima dessa é uma melhora de um classificador, e qualquer curva abaixo disso está fazendo um desserviço ao usuário. \n",
    "\n",
    "Sendo assim podemos também dizer o que seria um classificador perfeito. \n",
    "![](http://blog.yhat.com/static/img/roc-perfect.png 'Classificador Perfeito')\n",
    "\n",
    "Então quanto mais a curva do seu classificador se aproximar a essa, melhor será, porém em aprendizado de máquina deve sempre se ter cuidado com _overfitting_. Dessa forma, um bom classificador se parecerá com isso:\n",
    "![](http://blog.yhat.com/static/img/roc-pretty-good.png 'Bom Classificador')\n",
    "\n",
    "Agora para se calcular o quão bom ou ruim um classificador é calculamos a área embaixo da curva. E para comparar os classificadores basta comparar os valores embaixo da curva _ROC_. \n",
    "![](http://blog.yhat.com/static/img/roc-auc.png 'Área da curva ROC')\n",
    "\n",
    "---\n",
    "Lembrando que esse método foi pensado para classificadores binários, sendo assim para usa-lo em um classificador de multi-classes é necessário binarizar a saída. Uma curva pode ser desenhada por classe, mas uma também pode desenhar uma curva considerando cada elemento da matriz indicadora de classes como uma predição binária (_micro-averaging_).\n",
    "\n",
    "[Multi-class ROC curve](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculando a área da curva ROC \n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "knn_model = joblib.load('knnBacteria.sav')\n",
    "svm_model = joblib.load('svmBacteria.sav')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
