{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação da avaliação de modelos de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%autosave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comprimentocorpo' 'larguracorpo' 'comprimentoflagelo' 'larguraflagelo'\n",
      " 'Tipo' 'volumecorpo' 'volumeflagelo']\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset_bacteria.csv')\n",
    "dataset['volumecorpo'] = np.array(dataset['comprimentocorpo']) * np.pi*(np.array(dataset['larguracorpo'])/2)**2\n",
    "dataset['volumeflagelo'] = np.array(dataset['comprimentoflagelo']) * np.pi*(np.array(dataset['larguraflagelo'])/2)**2\n",
    "print(dataset.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando conjunto de teste e conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib # biblioteca para salvar os modelos\n",
    "\n",
    "Y = dataset.iloc[:, 4].values # Coluna Tipo\n",
    "X = dataset.iloc[:, [2, 3]].values # Features Selecionadas\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Modelo de classificação KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knnBacteria.sav']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "knn_classifier = neighbors.KNeighborsClassifier(5, 'uniform')\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Saving model to file\n",
    "joblib.dump(knn_classifier, 'knnBacteria.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Modelo de Classificação SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svmBacteria.sav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = SVC(kernel = 'rbf', gamma = 0.1)\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Saving model to file\n",
    "joblib.dump(svm_classifier, 'svmBacteria.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando modelos para avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  1 12]]\n",
      "\n",
      " [[13  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Importando modelo KNN\n",
    "knn_model = joblib.load('knnBacteria.sav')\n",
    "knn_y_pred = knn_model.predict(x_test)\n",
    "\n",
    "knn_confusion_matrix = confusion_matrix(y_test, knn_y_pred)\n",
    "print(knn_confusion_matrix)\n",
    "\n",
    "# Importando modelo SVM\n",
    "svm_model = joblib.load('svmBacteria.sav')\n",
    "svm_y_pred = svm_model.predict(x_test)\n",
    "\n",
    "svm_confusion_matrix = confusion_matrix(y_test, svm_y_pred)\n",
    "print('\\n', svm_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando modelos\n",
    "#### Pelo método de _micro-averaging_ e _macro-averaging_\n",
    "\n",
    "Baseando-se pela matrix de confusão, pode-se calcular a precisão micro e precisão macro com a seguinte estratégia:\n",
    "\n",
    "Tomando a matriz de confusão como a abaixo:\n",
    "![img](https://qph.ec.quoracdn.net/main-qimg-e73665ad4501b9da6d5611e7b6d8e7a2 \"Matriz de Confusão\")\n",
    "\n",
    "Podemos calcular a precisão do modelo com a seguinte fórmula:\n",
    "$$ PRE = \\frac{TP} {(TP + FP)} $$\n",
    "\n",
    "E então generalizar a matriz de confusão de classificação binária para uma classificação multi-classe. Onde o calculo da _micro-average_ calcula a performance e precisão e a _macro-average_ calcula a média das performances de cada classe individualmente.\n",
    "\n",
    "Para a _micro-averaging_ utilizamos a fórmula:\n",
    "$$ PRE_{micro} = \\frac{TP_1 + ... + TP_n} {TP_1 + ... + TP_n + FP_1 + ... + FP_n} $$\n",
    "\n",
    "E para a _macro-averaging_ utilizamos a seguinte fórmula:\n",
    "$$ PRE_{macro} = \\frac{PRE_1 + ... + PRE_n} {n} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular o valor da precisão micro e macro\n",
    "def evaluation_micro_macro (confusion_matrix):\n",
    "    TP_all = 0\n",
    "    FP_all = 0\n",
    "    pre_all = 0\n",
    "    n_classes = confusion_matrix.shape[0]\n",
    "    for i in range(n_classes):\n",
    "        TP_all += confusion_matrix[i][i]\n",
    "        next_row = (i + 1) % n_classes\n",
    "        FP_all += confusion_matrix[i][next_row]\n",
    "        last_row = (i + 2) % n_classes\n",
    "        FP_all += confusion_matrix[i][last_row]\n",
    "        pre_all += confusion_matrix[i][i] / (confusion_matrix[i][i] + confusion_matrix[i][next_row] + knn_confusion_matrix[i][last_row])\n",
    "\n",
    "    pre_micro = TP_all / (TP_all + FP_all)\n",
    "    pre_macro = pre_all / len(classes)\n",
    "    \n",
    "    return (pre_micro, pre_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo de classificação SVM\n"
     ]
    }
   ],
   "source": [
    "# Avaliando o modelo KNN pela estratégia de micro e macro averaging\n",
    "mima_knn = evaluation_micro_macro(knn_confusion_matrix)\n",
    "\n",
    "# Avaliando o modelo SVM pela estratégia de micro e macro averaging\n",
    "mima_svm = evaluation_micro_macro(svm_confusion_matrix)\n",
    "\n",
    "print ('Melhor modelo de classificação', 'KNN' if mima_knn > mima_svm else 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
